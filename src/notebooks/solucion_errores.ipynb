{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import time\n",
    "import xgboost as xgb\n",
    "from unidecode import unidecode\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "class data_processing():\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def procesado_lesionados(self, df):\n",
    "        '''Coge el dataframe de lesionados y le aplica un OneHotEncoder, pero sin usar la librería. Para tener en cuenta que jugadores\n",
    "        han participado en el encuentro de inicio o no. Es representativo ya que la no presencia de un jugador puede afectar en el resultado\n",
    "        de un partido'''\n",
    "        #Añade una fila de 1 para identificar que ese jugador ha estado lesionado en algún momento\n",
    "            \n",
    "        df['lesionados'] = pd.Series(np.ones(len(df)), index=df.index)\n",
    "        \n",
    "        \n",
    "        df_lesionados_id = df[['fixture_id', 'id_lesionado', 'lesionados']]\n",
    "        \n",
    "        #Elimino fila si hay missings en la columna de id_jugador_titular\n",
    "        df_lesionados_id = df_lesionados_id.dropna(subset=['id_lesionado'])\n",
    "        \n",
    "        #Pivota la tabla para convertir en una variable cada jugador. Para los partidos que el jugador no ha estado lesionado,\n",
    "        #se rellenará con un '0'. Dejo el índice de la forma correcta.\n",
    "        df_lesionados_id = df_lesionados_id.pivot( index= 'fixture_id', \n",
    "                                                columns = 'id_lesionado', \n",
    "                                                values = 'lesionados').fillna(0).reset_index()\n",
    "        df_lesionados_id.columns.name = None\n",
    "        \n",
    "        #Transformo los valores '1' y '0' a int.\n",
    "        df_lesionados_id.iloc[:,1:] =df_lesionados_id.iloc[:,1:].astype(int)\n",
    "        \n",
    "        #Añado al nombre de las variables de los id de jugadores 'les-' para identificar que es la variable de lesionados.\n",
    "        df_lesionados_id = df_lesionados_id.rename(columns={col: f'les-{col}' for col in df_lesionados_id.iloc[:,1:]})\n",
    "        \n",
    "        return df_lesionados_id\n",
    "\n",
    "\n",
    "    def procesado_titulares(self, df):\n",
    "        '''Coge el dataframe de alineaciones y le aplica un OneHotEncoder, pero sin usar la librería. Para tener en cuenta que jugadores\n",
    "        han participado en el encuentro de inicio o no. Es representativo ya que la no presencia de un jugador puede afectar en el resultado\n",
    "        de un partido'''    \n",
    "\n",
    "        #Añade una fila de 1 para identificar que ese jugador ha estado lesionado en algún momento\n",
    "        df['titular'] = pd.Series(np.ones(len(df)), index=df.index)\n",
    "        df_alineaciones_id = df[['fixture_id', 'id_jugador_titular', 'titular']]\n",
    "        #Elimino fila si hay missings en la columna de id_jugador_titular\n",
    "        df_alineaciones_id = df_alineaciones_id.dropna(subset=['id_jugador_titular'])\n",
    "        #Pivota la tabla para convertir en una variable cada jugador. Para los partidos que el jugador no ha estado lesionado,\n",
    "        #se rellenará con un '0'. Dejo el índice de la forma correcta.\n",
    "        df_alineaciones_id = df_alineaciones_id.pivot( index= 'fixture_id', \n",
    "                                                columns = 'id_jugador_titular', \n",
    "                                                values = 'titular').fillna(0).reset_index()\n",
    "        df_alineaciones_id.columns.name = None\n",
    "        \n",
    "        #Me cargo un jugador con id nulo (hay que revisarlo después del procesado)\n",
    "        df_alineaciones_id = df_alineaciones_id.drop(df_alineaciones_id.columns[1], axis=1)\n",
    "        \n",
    "        #Transformo los valores '1' y '0' a int.\n",
    "        df_alineaciones_id.iloc[:,1:]=df_alineaciones_id.iloc[:,1:].astype(int)\n",
    "        \n",
    "        #Añado al nombre de las variables de los id de jugadores 'les-' para identificar que es la variable de lesionados.\n",
    "        df_alineaciones_id = df_alineaciones_id.rename(columns={col: f'titu-{col}' for col in df_alineaciones_id.iloc[:,1:]})\n",
    "        \n",
    "        return df_alineaciones_id\n",
    "    \n",
    "    def procesado_estadisticas(self, df):\n",
    "        '''Procesado de todas las estadisticas que se han extraido, y que ocurren dentro de un partido.'''\n",
    "        #Elimino las filas en las que la API no me devuelve un solo valor(ha pasado)\n",
    "        rows_with_all_missing = df.iloc[:, :-1].isna().all(axis=1)\n",
    "        df = df[~rows_with_all_missing]\n",
    "        #Renombro dos columnas mal nombradas (no es el dato que dice la columna)\n",
    "        df = df.rename(columns={'pass_precision_local': 'total_pass_local',\n",
    "                                'pass_precision_away': 'total_pass_away',\n",
    "                            'fixture_id_2': 'fixture_id'})\n",
    "        #Transformo los datos de posesion a float para poder usarlos de forma más sencilla\n",
    "        df['ball_possession_local'] = df['ball_possession_local'].str.replace('%','').astype(float)\n",
    "        df['ball_possession_away'] = df['ball_possession_away'].str.replace('%', '').astype(float)\n",
    "\n",
    "        df['ball_possession_local'] = df['ball_possession_local']/100\n",
    "        df['ball_possession_away'] = df['ball_possession_away']/100\n",
    "        # Convertir columna a tipo numérico. Esto es porque en las tarjetas amarillas habia datos erroneos (con porcntaje)\n",
    "        df['yellow_cards_local'] = pd.to_numeric(df['yellow_cards_local'], errors='coerce')\n",
    "        df['yellow_cards_away'] = pd.to_numeric(df['yellow_cards_away'], errors='coerce')\n",
    "\n",
    "        # Filtro filas con NaN en la columna en cuestión y las elimino\n",
    "        rows_with_nan = df['yellow_cards_local'].isna() | df['yellow_cards_away'].isna()\n",
    "        df = df[~rows_with_nan]\n",
    "        #Cambio los missings por 0, ya que cuando el valor es 0 la api devuelve null.\n",
    "        df.fillna(0, inplace = True)\n",
    "        #Cambio todas las columnas que quiero que sean número entero para trabajar mejor con ellos\n",
    "        cols_to_int = ['shots_on_goal_local', 'shots_on_goal_away', 'shots_off_goal_local', 'shots_off_goal_away', \n",
    "                'total_shots_local', 'total_shots_away', 'blocked_shots_local', 'blocked_shots_away', \n",
    "                'shots_insidebox_local', 'shots_insidebox_away', 'shots_outsidebox_local', 'shots_outsidebox_away', \n",
    "                'fouls_local', 'fouls_away', 'corners_local', 'corners_away', 'offsides_local', 'offsides_away', \n",
    "                'yellow_cards_local', 'yellow_cards_away', 'red_cards_local', 'red_cards_away', 'goalkeeper_saves_local', \n",
    "                'goalkeeper_saves_away', 'total_pass_local', 'total_pass_away']\n",
    "        df[cols_to_int] = df[cols_to_int].astype(int)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def procesado_datos_generales(self, df):\n",
    "        '''Eliminación de missings en los goles (ya que si no hay goles lo considera como missing), y cambiar el tipo de los goles\n",
    "        a favor/en contra'''\n",
    "        #Sustituimos los missings por 0, ya que esos missings significa que ha habido 0 goles\n",
    "        df['goles_descanso_local'] = df['goles_descanso_local'].fillna(0)\n",
    "        df['goles_descanso_visitante'] = df['goles_descanso_visitante'].fillna(0)\n",
    "        #Cambio el tipo de float a int, ya que no puede haber goles decimales\n",
    "        df['goles_descanso_local'] = df['goles_descanso_local'].astype(int)\n",
    "        df['goles_descanso_visitante'] = df['goles_descanso_visitante'].astype(int)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def ruta_cuotas(self):\n",
    "        return [\n",
    "        '../data/raw_files/cuotas/SP1-2012.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2012.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2013.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2013.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2014.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2014.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2015.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2015.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2016.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2016.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2017.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2017.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2018.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2018.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2019.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2019.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2020.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2020.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2021.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2021.csv',\n",
    "        '../data/raw_files/cuotas/SP1-2022.csv',\n",
    "        '../data/raw_files/cuotas/SP2-2022.csv'\n",
    "    ]\n",
    "    \n",
    "    def procesado_cuotas(self, file_names, df_ids):\n",
    "        equivalencia_nombres = {\n",
    "            'Celta':'Celta Vigo',\n",
    "            'Mallorca':'Mallorca',\n",
    "            'Sevilla': 'Sevilla',\n",
    "            'Ath Bilbao': 'Athletic Club',\n",
    "            'Barcelona':'Barcelona',\n",
    "            'Levante':'Levante',\n",
    "            'Real Madrid': 'Real Madrid',\n",
    "            'La Coruna': 'Deportivo La Coruna',\n",
    "            'Vallecano': 'Rayo Vallecano',\n",
    "            'Zaragoza': 'Zaragoza',\n",
    "            'Betis': 'Real Betis',\n",
    "            'Espanol':'Espanyol',\n",
    "            'Malaga':'Malaga',\n",
    "            'Sociedad':'Real Sociedad',\n",
    "            'Getafe':'Getafe',\n",
    "            'Granada':'Granada CF',\n",
    "            'Osasuna':'Osasuna',\n",
    "            'Valencia':'Valencia',\n",
    "            'Ath Madrid':'Atletico Madrid',\n",
    "            'Valladolid':'Valladolid',\n",
    "            'Barcelona B':'Barcelona B',\n",
    "            'Mirandes':'Mirandes',\n",
    "            'Villarreal':'Villarreal',\n",
    "            'Girona':'Girona',\n",
    "            'Lugo':'Lugo',\n",
    "            'Xerez':'Xerez',\n",
    "            'Alcorcon':'Alcorcon',\n",
    "            'Elche':'Elche',\n",
    "            'Numancia':'Numancia',\n",
    "            'Santander':'Racing Santander',\n",
    "            'Murcia':'Real Murcia',\n",
    "            'Almeria':'Almeria',\n",
    "            'Guadalajara':'Guadalajara',\n",
    "            'Huesca':'Huesca',\n",
    "            'Las Palmas':'Las Palmas',\n",
    "            'Ponferradina':'Ponferradina',\n",
    "            'Real Madrid B':'Real Madrid II',\n",
    "            'Recreativo':'Recreativo Huelva',\n",
    "            'Sabadell':'Sabadell',\n",
    "            'Sp Gijon':'Sporting Gijon',\n",
    "            'Cordoba':'Cordoba',\n",
    "            'Hercules':'Hércules',\n",
    "            'Jaen':'Real Jaén',\n",
    "            'Alaves':'Alaves',\n",
    "            'Eibar':'Eibar',\n",
    "            'Tenerife':'Tenerife',\n",
    "            'Albacete':'Albacete',\n",
    "            'Leganes':'Leganes',\n",
    "            'Llagostera':'Llagostera',\n",
    "            'Gimnastic':'Gimnastic',\n",
    "            'Oviedo':'Oviedo',\n",
    "            'Ath Bilbao B':'Athletic Club II',\n",
    "            'Sevilla B':'Sevilla Atletico',\n",
    "            'Reus Deportiu':'Reus',\n",
    "            'Cadiz':'Cadiz',\n",
    "            'UCAM Murcia':'Ucam Murcia',\n",
    "            'Lorca':'Lorca',\n",
    "            'Leonesa':'Cultural Leonesa',\n",
    "            'Extremadura UD':'Extremadura',\n",
    "            'Rayo Majadahonda':'Rayo Majadahonda',\n",
    "            'Fuenlabrada':'Fuenlabrada',\n",
    "            'Castellon':'Castellón',\n",
    "            'Cartagena':'FC Cartagena',\n",
    "            'Logrones':'UD Logroñés',\n",
    "            'Sociedad B':'Real Sociedad II',\n",
    "            'Ibiza':'Ibiza',\n",
    "            'Amorebieta':'Amorebieta',\n",
    "            'Burgos':'Burgos',\n",
    "            'Villarreal B':'Villarreal II',\n",
    "            'Andorra':'FC Andorra'\n",
    "        }\n",
    "    \n",
    "        def select_columns_and_add_season(df, file_name):\n",
    "            # Extraer año del nombre del archivo\n",
    "            year = file_name.split('-')[1][:4]\n",
    "\n",
    "            # Crear un diccionario que contenga los nombres de los equipos como claves y sus IDs como valores\n",
    "            equipo_id = {}\n",
    "            for index, row in df_ids.iterrows():\n",
    "                equipo_id[row['equipo_jugador']] = row['id_equipo']\n",
    "\n",
    "            # Reemplazar los nombres de los equipos por sus IDs correspondientes utilizando el diccionario de equivalencias y el diccionario equipo_id\n",
    "            df['HomeTeam'] = df['HomeTeam'].map(equivalencia_nombres).map(equipo_id)\n",
    "            df['AwayTeam'] = df['AwayTeam'].map(equivalencia_nombres).map(equipo_id)\n",
    "\n",
    "            # Seleccionar columnas requeridas\n",
    "            df_selected = df[['HomeTeam', 'AwayTeam', 'B365H', 'B365D', 'B365A']]\n",
    "\n",
    "            # Añadir columna \"season\" con el año extraído\n",
    "            df_selected['season'] = int(year)\n",
    "\n",
    "            # Eliminar filas con valores NaN\n",
    "            df_selected.dropna(inplace=True)\n",
    "\n",
    "            return df_selected\n",
    "\n",
    "        # Lista para guardar los dataframes procesados\n",
    "        processed_dfs = []\n",
    "\n",
    "        # Iterar sobre los nombres de archivo\n",
    "        for file_name in file_names:\n",
    "            # Leer archivo CSV en un dataframe\n",
    "            df = pd.read_csv(file_name)\n",
    "\n",
    "            # Aplicar la función select_columns_and_add_season y renombrar las columnas\n",
    "            df_processed = select_columns_and_add_season(df, file_name).rename(columns={'B365H': 'odd_1', 'B365D': 'odd_x', 'B365A': 'odd_2'})\n",
    "\n",
    "            # Agregar el dataframe procesado a la lista\n",
    "            processed_dfs.append(df_processed)\n",
    "\n",
    "        # Concatenar todos los dataframes procesados en uno solo\n",
    "        final_df = pd.concat(processed_dfs, ignore_index=True)\n",
    "        final_df = final_df.dropna(how='any')\n",
    "        final_df['HomeTeam'] = final_df['HomeTeam'].astype(int)\n",
    "        final_df['AwayTeam'] = final_df['AwayTeam'].astype(int)\n",
    "\n",
    "        return final_df\n",
    "        \n",
    "    def creacion_df_final(self, df_lesionados, df_alineaciones, df_datos_partidos, df_estadisticas, df_cuotas):\n",
    "        '''Esta función hace un merge de todos los datos sacados anteriormente'''\n",
    "        #Comenzamos la unión de dataframes, empezando por los datos de partidos y estadísticas\n",
    "        df_final = pd.merge(df_datos_partidos, df_estadisticas, on='fixture_id', how='left')\n",
    "        \n",
    "        #Elimino las filas en las que la API no me devuelve un solo valor(ha pasado)\n",
    "        rows_with_all_missing = df_final.loc[:, 'shots_on_goal_local':].isna().all(axis=1)\n",
    "        df_final = df_final[~rows_with_all_missing]\n",
    "        \n",
    "        #Unimos el df resultante con el de lesionados\n",
    "        df_final = pd.merge(df_final,df_lesionados, on='fixture_id', how = 'left')\n",
    "        #Relleno los missings con 0, ya que significa que en esos partidos no ha habido lesionados\n",
    "        df_final = df_final.fillna(0)\n",
    "        \n",
    "        #Unimos el df_final con el de alineaciones, que es el que faltaría.\n",
    "        df_final = pd.merge(df_final, df_alineaciones, on='fixture_id', how='left')\n",
    "        #Relleno los missings con 0, ya que significa que en esos partidos no habría participado ese jugador\n",
    "        df_final = df_final.fillna(0)\n",
    "        \n",
    "        #Unimos el df_final con el de odds\n",
    "        df_final = pd.merge(df_final, df_cuotas, left_on=['id_equipo_local', 'id_equipo_visitante', 'season'], \n",
    "                            right_on=['HomeTeam', 'AwayTeam', 'season'], how='inner')\n",
    "        \n",
    "        #Eliminamos filas con NaN\n",
    "        df_final = df_final.dropna(how='any')\n",
    "        df_final = df_final.drop(['HomeTeam','AwayTeam'], axis=1)\n",
    "        \n",
    "        \n",
    "        df_final = df_final.reset_index()\n",
    "\n",
    "        #Para agilizar tiempos en métedos que necesitan esta tabla para usarse, ya que tarda un poco en ejecutarse.\n",
    "        #df_final.to_csv('df_partidos_completo.csv', index=False)\n",
    "\n",
    "\n",
    "        \n",
    "        return df_final\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    #Las funciones siguientes tendrán únicamente la utilidad de crear datos nuevos.\n",
    "    def buscar_jugador(self, id_equipo, temporada_equipo):\n",
    "        ''' Esta función únicamente será llamada para localizar los ids de jugadores y poder crear los datos nuevos'''\n",
    "\n",
    "        df = pd.read_csv(\"df_diccionario_jugadores.csv\")\n",
    "\n",
    "        # Filtre el DataFrame original utilizando los valores de los parámetros\n",
    "        filtro = (df['id_equipo'] == id_equipo) & (df['temporada_equipo'] == temporada_equipo)\n",
    "        df_filtrado = df[filtro]\n",
    "\n",
    "        # Devuelva el DataFrame filtrado\n",
    "        return df_filtrado\n",
    "\n",
    "    def buscar_equipo(self, nombres):\n",
    "        ''' Esta función únicamente será llamada para localizar los ids delos equipos y poder crear los datos nuevos. Acepta una lista de nombres o\n",
    "         un único nombre '''\n",
    "        # Cargo el diccionario de ids que tengo y fue descargado. Es el mismo que de jugadores\n",
    "        equipos = pd.read_csv(\"df_diccionario_jugadores.csv\")\n",
    "        # Elimino acentos de los nombres de los equipos en el DataFrame aplicando unidecode. También se quedan en minúsculas\n",
    "        equipos['nombre_equipo'] = equipos['equipo_jugador'].apply(lambda x: unidecode(x.lower()))\n",
    "        \n",
    "        if isinstance(nombres, str):\n",
    "            # Eliminar las marcas diacríticas del nombre introducido\n",
    "            equipo = unidecode(nombres.lower())\n",
    "            # Busco los equipos cuyo nombre contenga la cadena de texto introducida como parámetro\n",
    "            equipos_coincidentes = equipos[equipos['nombre_equipo'].str.contains(nombres, case=False)]\n",
    "            #Elimino los jugadores duplicados, porque pueden salir jugadores repetidos si participaron más de 1 temporada\n",
    "            equipos_coincidentes = equipos_coincidentes.drop_duplicates(subset='id_equipo')\n",
    "            # Devuelve una tabla con los nombres y los ids de los jugadores encontrados\n",
    "            return equipos_coincidentes[['nombre_equipo', 'id_equipo']]\n",
    "        \n",
    "        elif isinstance(nombres, list):\n",
    "            resultados = []\n",
    "            # Busco cada id de los jugadores en la lista\n",
    "            for n in nombres:\n",
    "                # Elimino acentos del nombre introducido\n",
    "                equipo = unidecode(n.lower())\n",
    "                # Busco los jugadores cuyo nombre contenga la cadena de texto introducida como parámetro\n",
    "                equipos_coincidentes = equipos[equipos['nombre_equipo'].str.contains(n, case=False)]\n",
    "                # Elimino jugadores duplicados en función del id\n",
    "                equipos_coincidentes = equipos_coincidentes.drop_duplicates(subset='id_equipo')\n",
    "                # Añado los resultados a la lista de resultados\n",
    "                for i, row in equipos_coincidentes.iterrows():\n",
    "                    resultados.append([row['nombre_equipo'], row['id_equipo']])\n",
    "            # Devuelvo una tabla con los nombres y los IDs de los jugadores encontrados\n",
    "            return pd.DataFrame(resultados, columns=['nombre_equipo', 'id_equipo'])\n",
    "        \n",
    "        else: return 'Introduce una lista de nombres o un nombre único'\n",
    "\n",
    "    \n",
    "    def nombre_arbitro_correcto(self, nombre):\n",
    "\n",
    "        arbitros = pd.read_csv('df_partidos_completo.csv')\n",
    "        # Elimino los acentos del nombre introducido\n",
    "        arbitro = unidecode(nombre.lower())\n",
    "        # Busco los equipos cuyo nombre contenga la cadena de texto introducida como parámetro\n",
    "        arbitros_coincidentes = arbitros[arbitros['arbitro'].str.contains(nombre, case=False)]\n",
    "        #Elimino los arbitros duplicados, porque pueden salir árbitros repetidos si participaron más de 1 temporada\n",
    "        arbitros_coincidentes = arbitros_coincidentes.drop_duplicates(subset='arbitro')\n",
    "        if len(arbitros_coincidentes) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            # Obtengo el índice de la fila correspondiente al árbitro\n",
    "            indice = arbitros_coincidentes.index[0]\n",
    "            # Obtengo el nombre del árbitro con el formato adecuado\n",
    "            nombre_completo = arbitros.loc[indice, 'arbitro']\n",
    "            # Devuelve el nombre del árbitro con el formato adecuado\n",
    "            return nombre_completo\n",
    "\n",
    "\n",
    "    def nombre_estadio_correcto(self, nombre):\n",
    "        estadios = pd.read_csv('df_partidos_completo.csv')\n",
    "        # Elimino los acentos del nombre introducido\n",
    "        estadio = unidecode(nombre.lower())\n",
    "        # Busco los equipos cuyo nombre contenga la cadena de texto introducida como parámetro\n",
    "        estadios_coincidentes = estadios[estadios['estadio'].str.contains(nombre, case=False)]\n",
    "        #Elimino los arbitros duplicados, porque pueden salir estadios repetidos si participaron más de 1 temporada\n",
    "        estadios_coincidentes = estadios_coincidentes.drop_duplicates(subset='estadio')\n",
    "        if len(estadios_coincidentes) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            # Obtengo el índice de la fila correspondiente al estadio\n",
    "            indice = estadios_coincidentes.index[0]\n",
    "            # Obtengo el nombre del estadio con el formato adecuado\n",
    "            nombre_completo = estadios.loc[indice, 'estadio']\n",
    "            # Devuelve el nombre del estadio con el formato adecuado\n",
    "            return nombre_completo\n",
    "    \n",
    "    def creacion_datos_nuevos(self, df_partidos,id_equipo_local, id_equipo_visitante,odd_1, odd_x, odd_2, arbitro, estadio, season, ids_lesionados, ids_titulares):\n",
    "        #Leo el csv donde estan todos los datos completos de los partidos. Se ha creado con la función creacion_df_final()\n",
    "        \n",
    "        #Creo los datos de estadisticas que se preveen con la media de datos de los últimos 3 partidos en casa o de visitante\n",
    "        shots_on_goal_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_on_goal_local'].shift(1) +  \\\n",
    "                                df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_on_goal_local'].shift(2) +  \\\n",
    "                                df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_on_goal_local'].shift(3))\n",
    "        shots_on_goal_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_on_goal_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_on_goal_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_on_goal_away'].shift(3))\n",
    "        shots_off_goal_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_off_goal_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_off_goal_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_off_goal_local'].shift(3))\n",
    "        shots_off_goal_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_off_goal_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_off_goal_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_off_goal_away'].shift(3))\n",
    "        total_shots_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'total_shots_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'total_shots_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'total_shots_local'].shift(3))\n",
    "        total_shots_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'total_shots_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'total_shots_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'total_shots_away'].shift(3))\n",
    "        blocked_shots_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'blocked_shots_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'blocked_shots_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'blocked_shots_local'].shift(3))\n",
    "        blocked_shots_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'blocked_shots_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'blocked_shots_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'blocked_shots_away'].shift(3))\n",
    "        shots_insidebox_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_insidebox_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_insidebox_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_insidebox_local'].shift(3))\n",
    "        shots_insidebox_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_insidebox_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_insidebox_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_insidebox_away'].shift(3))\n",
    "        shots_outsidebox_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_outsidebox_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_outsidebox_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'shots_outsidebox_local'].shift(3))\n",
    "        shots_outsidebox_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_outsidebox_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_outsidebox_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'shots_outsidebox_away'].shift(3))\n",
    "        fouls_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'fouls_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'fouls_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'fouls_local'].shift(3))\n",
    "        fouls_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'fouls_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'fouls_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'fouls_away'].shift(3))\n",
    "        corners_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'corners_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'corners_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'corners_local'].shift(3))\n",
    "        corners_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'corners_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'corners_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'corners_away'].shift(3))\n",
    "        offsides_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'offsides_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'offsides_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'offsides_local'].shift(3))\n",
    "        offsides_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'offsides_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'offsides_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'offsides_away'].shift(3))\n",
    "        ball_possession_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'ball_possession_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'ball_possession_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'ball_possession_local'].shift(3))\n",
    "        ball_possession_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'ball_possession_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'ball_possession_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'ball_possession_away'].shift(3))\n",
    "        yellow_cards_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'yellow_cards_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'yellow_cards_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'yellow_cards_local'].shift(3))\n",
    "        yellow_cards_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'yellow_cards_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'yellow_cards_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'yellow_cards_away'].shift(3))\n",
    "        red_cards_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'red_cards_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'red_cards_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'red_cards_local'].shift(3))\n",
    "        red_cards_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'red_cards_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'red_cards_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'red_cards_away'].shift(3))\n",
    "        goalkeeper_saves_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'goalkeeper_saves_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'goalkeeper_saves_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'goalkeeper_saves_local'].shift(3))\n",
    "        goalkeeper_saves_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'goalkeeper_saves_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'goalkeeper_saves_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'goalkeeper_saves_away'].shift(3))\n",
    "        total_pass_local = np.mean(df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'total_pass_local'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'total_pass_local'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_local'] == id_equipo_local, 'total_pass_local'].shift(3))\n",
    "        total_pass_away = np.mean(df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'total_pass_away'].shift(1) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'total_pass_away'].shift(2) +  \\\n",
    "                                    df_partidos.loc[df_partidos['id_equipo_visitante'] == id_equipo_visitante, 'total_pass_away'].shift(3))\n",
    "        \n",
    "        #Creo un dataframe de solo estadísticas más los datos de arbitro, estadio, ids, season (todos menos lesionados y titulares)\n",
    "        df_datos_nuevos = pd.DataFrame({\n",
    "                                        'id_equipo_local': id_equipo_local,\n",
    "                                            'id_equipo_visitante': id_equipo_visitante,\n",
    "                                            'arbitro': arbitro,\n",
    "                                            'estadio': estadio,\n",
    "                                            'season': season,\n",
    "                                        'shots_on_goal_local':shots_on_goal_local,\n",
    "                                        'shots_on_goal_away':shots_on_goal_away,\n",
    "                                        'shots_off_goal_local':shots_off_goal_local,\n",
    "                                        'shots_off_goal_away':shots_off_goal_away,\n",
    "                                        'total_shots_local':total_shots_local,\n",
    "                                        'total_shots_away':total_shots_away,\n",
    "                                        'blocked_shots_local':blocked_shots_local,\n",
    "                                        'blocked_shots_away':blocked_shots_away,\n",
    "                                        'shots_insidebox_local':shots_insidebox_local,\n",
    "                                        'shots_insidebox_away':shots_insidebox_away,\n",
    "                                        'shots_outsidebox_local':shots_outsidebox_local,\n",
    "                                        'shots_outsidebox_away':shots_outsidebox_away,\n",
    "                                        'fouls_local':fouls_local,\n",
    "                                        'fouls_away':fouls_away,\n",
    "                                        'corners_local':corners_local,\n",
    "                                        'corners_away':corners_away,\n",
    "                                        'offsides_local':offsides_local,\n",
    "                                        'offsides_away':offsides_away,\n",
    "                                        'ball_possession_local':ball_possession_local,\n",
    "                                        'ball_possession_away':ball_possession_away,\n",
    "                                        'yellow_cards_local':yellow_cards_local,\n",
    "                                        'yellow_cards_away':yellow_cards_away,\n",
    "                                        'red_cards_local':red_cards_local,\n",
    "                                        'red_cards_away':red_cards_away,\n",
    "                                        'goalkeeper_saves_local':goalkeeper_saves_local,\n",
    "                                        'goalkeeper_saves_away':goalkeeper_saves_away,\n",
    "                                        'total_pass_local':total_pass_local,\n",
    "                                        'total_pass_away':total_pass_away\n",
    "                                        }, index = [0])\n",
    "        \n",
    "        #Creo un dataframe solo con las columnas de lesionados y las relleno con 0 todas\n",
    "        #Primero localizo todas las columnas de df_partidos\n",
    "        columns_les = []\n",
    "        for col in df_partidos.columns:\n",
    "            if 'les-' in col:\n",
    "                columns_les.append(col)\n",
    "        #Relleno con 0 y creo el dataframe de lesionados\n",
    "        valores = {col: 0 for col in columns_les}\n",
    "        df_lesionados_nuevos = pd.DataFrame([valores])\n",
    "        \n",
    "        #Hago el mismo proceso con un dataframe de titulares\n",
    "        columns_titus = []\n",
    "        for col in df_partidos.columns:\n",
    "            if 'titu-' in col:\n",
    "                columns_titus.append(col)\n",
    "        valores_titu = {col: 0 for col in columns_titus}\n",
    "        df_titulares_nuevos = pd.DataFrame([valores_titu])\n",
    "        \n",
    "        #Concateno los 3 dataframe para obtener el dataframe de datos final\n",
    "        df_datos_nuevos_final = pd.concat([df_datos_nuevos, df_lesionados_nuevos,df_titulares_nuevos], axis = 1)\n",
    "        \n",
    "        #Añado los prefijos y sufijos necesarios para localizar los ids de lesionados y titulares en la tabla\n",
    "        ids_lesionado_prefijo = ['les-{}'.format(id) for id in ids_lesionados]\n",
    "        ids_titular_prefijo = ['titu-{}{}'.format(id,'.0') for id in ids_titulares]\n",
    "        \n",
    "        #Y sustituyo el valor correspondiente por 1, ya que o estan lesionados en ese partido o van a jugar\n",
    "        for id_les in ids_lesionado_prefijo:\n",
    "            df_datos_nuevos_final.loc[0, id_les] = 1\n",
    "        for id_titu in ids_titular_prefijo:\n",
    "            df_datos_nuevos_final.loc[0, id_titu] = 1\n",
    "            \n",
    "        \n",
    "        df_datos_nuevos_final['odd_1'] = odd_1\n",
    "        df_datos_nuevos_final['odd_x'] = odd_x\n",
    "        df_datos_nuevos_final['odd_2'] = odd_2\n",
    "\n",
    "        return df_datos_nuevos_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processing = data_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datos_generales = pd.read_csv('../data/raw_files/datos_generales_fx.csv')\n",
    "df_estadisticas = pd.read_csv('../data/raw_files/df_estadisticas.csv')\n",
    "df_alineaciones = pd.read_csv('../data/raw_files/datos_alineaciones.csv')\n",
    "df_lesionados = pd.read_csv('../data/raw_files/datos_lesionados.csv')\n",
    "df_dicc_equipos = pd.read_csv('../data/raw_files/df_dicc_equipos.csv')\n",
    "cuotas = data_processing.ruta_cuotas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7155"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_datos_generales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['season'] = int(year)\n",
      "C:\\Users\\gonve\\AppData\\Local\\Temp\\ipykernel_46484\\3417217326.py:237: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_datos_generales_procesado = data_processing.procesado_datos_generales(df_datos_generales)\n",
    "\n",
    "#Procesamiento de las estadisticas de los partidos\n",
    "df_estadisticas_procesado = data_processing.procesado_estadisticas(df_estadisticas)\n",
    "#Procesamiento de las alineaciones de los partidos\n",
    "df_alineaciones_procesado = data_processing.procesado_titulares(df_alineaciones)\n",
    "#Procesamiento de los lesionados de los partidos\n",
    "df_lesionados_procesado = data_processing.procesado_lesionados(df_lesionados)\n",
    "#Procesamiento de los datos de las cuotas\n",
    "df_cuotas_procesado = data_processing.procesado_cuotas(cuotas,df_dicc_equipos)\n",
    "#Unión de los 4 dataframes anteriores, y realización de limpieza e imputación de missings si los hubiera\n",
    "df_union_procesado = data_processing.creacion_df_final(df_lesionados=df_lesionados_procesado, \n",
    "                                                       df_alineaciones=df_alineaciones_procesado,\n",
    "                                                        df_datos_partidos=df_datos_generales_procesado,\n",
    "                                                        df_estadisticas=df_estadisticas_procesado,\n",
    "                                                        df_cuotas = df_cuotas_procesado)\n",
    "#Creación de nuevas variables interesantes para el desempeño del modelo\n",
    "#df_final = data_processing.creacion_nuevas_variables(df_union_procesado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id_equipo_local</th>\n",
       "      <th>id_equipo_visitante</th>\n",
       "      <th>goles_local</th>\n",
       "      <th>goles_visitante</th>\n",
       "      <th>resultado</th>\n",
       "      <th>arbitro</th>\n",
       "      <th>fixture_id</th>\n",
       "      <th>fecha_timestamp</th>\n",
       "      <th>goles_descanso_local</th>\n",
       "      <th>...</th>\n",
       "      <th>titu-337011.0</th>\n",
       "      <th>titu-337031.0</th>\n",
       "      <th>titu-337523.0</th>\n",
       "      <th>titu-338295.0</th>\n",
       "      <th>titu-341700.0</th>\n",
       "      <th>titu-347886.0</th>\n",
       "      <th>titu-380261.0</th>\n",
       "      <th>odd_1</th>\n",
       "      <th>odd_x</th>\n",
       "      <th>odd_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8157</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jose Antonio Lopez Toca, Spain</td>\n",
       "      <td>878641</td>\n",
       "      <td>1677873600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>530</td>\n",
       "      <td>536</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Guillermo Cuadra Fernandez, Spain</td>\n",
       "      <td>878172</td>\n",
       "      <td>1677960000</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.67</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>546</td>\n",
       "      <td>547</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Juan Martinez Munuera, Spain</td>\n",
       "      <td>878175</td>\n",
       "      <td>1677934800</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>723</td>\n",
       "      <td>533</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Pablo Gonzales Fuertes, Spain</td>\n",
       "      <td>878176</td>\n",
       "      <td>1677942900</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>798</td>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>José Luis Munuera Montero, Spain</td>\n",
       "      <td>878179</td>\n",
       "      <td>1677951000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id_equipo_local  id_equipo_visitante  goles_local  goles_visitante  \\\n",
       "0      0             8157                  534            0                0   \n",
       "1      1              530                  536            6                1   \n",
       "2      2              546                  547            3                2   \n",
       "3      3              723                  533            0                2   \n",
       "4      4              798                  797            0                1   \n",
       "\n",
       "   resultado                            arbitro  fixture_id  fecha_timestamp  \\\n",
       "0          0     Jose Antonio Lopez Toca, Spain      878641       1677873600   \n",
       "1          1  Guillermo Cuadra Fernandez, Spain      878172       1677960000   \n",
       "2          1       Juan Martinez Munuera, Spain      878175       1677934800   \n",
       "3          2      Pablo Gonzales Fuertes, Spain      878176       1677942900   \n",
       "4          2   José Luis Munuera Montero, Spain      878179       1677951000   \n",
       "\n",
       "   goles_descanso_local  ...  titu-337011.0 titu-337031.0  titu-337523.0  \\\n",
       "0                     0  ...            0.0           0.0            0.0   \n",
       "1                     2  ...            0.0           0.0            0.0   \n",
       "2                     3  ...            0.0           0.0            0.0   \n",
       "3                     0  ...            0.0           0.0            0.0   \n",
       "4                     0  ...            0.0           0.0            0.0   \n",
       "\n",
       "   titu-338295.0  titu-341700.0  titu-347886.0  titu-380261.0  odd_1  odd_x  \\\n",
       "0            0.0            0.0            0.0            0.0   2.75    2.9   \n",
       "1            0.0            0.0            0.0            0.0   1.67    3.6   \n",
       "2            0.0            0.0            0.0            0.0   2.75    3.0   \n",
       "3            0.0            0.0            0.0            0.0   3.50    3.6   \n",
       "4            0.0            0.0            0.0            0.0   1.70    3.4   \n",
       "\n",
       "   odd_2  \n",
       "0   2.88  \n",
       "1   5.25  \n",
       "2   2.80  \n",
       "3   2.05  \n",
       "4   5.75  \n",
       "\n",
       "[5 rows x 3743 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union_procesado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('../data/processed_files/df_datos_completos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividimos en los datos de entrenamiento y la clasificación de los datos de entrenamiento que usaremos para entrenar el modelo\n",
    "X = df_final.drop(['index','fixture_id','resultado', 'goles_local', 'goles_visitante','goles_descanso_local','goles_descanso_visitante','fecha_timestamp' ], axis=1)\n",
    "y = df_final['resultado']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para codificar la columna 'arbitro' con OneHotEncoder\n",
    "arbitro_pipeline = Pipeline([\n",
    "    ('onehot', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline para codificar la columna 'estadio' con TargetEncoder\n",
    "estadio_pipeline = Pipeline([\n",
    "    ('target', TargetEncoder())\n",
    "])\n",
    "\n",
    "# ColumnTransformer para aplicar los pipelines a las columnas correspondientes\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('arbitro', arbitro_pipeline, ['arbitro']),\n",
    "    ('estadio', estadio_pipeline, ['estadio']),\n",
    "    ], remainder = \"passthrough\")\n",
    "\n",
    "# Pipeline final con el preprocesamiento y el modelo RandomForestClassifier\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', PCA()),\n",
    "    ('xgb', xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "xgb_param = {\n",
    "'pca__n_components': [12,30,35],\n",
    "'xgb__n_estimators': [300, 500, 700],\n",
    "'xgb__learning_rate': [0.1],\n",
    "'xgb__max_depth': [27,25],\n",
    "'xgb__subsample': [0.5, 0.8],\n",
    "'xgb__colsample_bytree': [0.5, 0.6],\n",
    "'xgb__min_child_weight': [1, 2],\n",
    "'xgb__gamma': [0]\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(\n",
    "                        pipeline_xgb,\n",
    "                        xgb_param,\n",
    "                        cv=3,\n",
    "                        scoring=\"accuracy\",\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of     id_equipo_local  id_equipo_visitante  \\\n",
       "0              8157                  534   \n",
       "1               530                  536   \n",
       "2               546                  547   \n",
       "3               723                  533   \n",
       "4               798                  797   \n",
       "5              9580                  715   \n",
       "6               726                  539   \n",
       "7               799                  718   \n",
       "8               719                  545   \n",
       "9               720                  540   \n",
       "10              543                  541   \n",
       "11              716                  732   \n",
       "12              535                 4665   \n",
       "13              722                  731   \n",
       "14             4907                 5262   \n",
       "15              537                 9390   \n",
       "16             9595                  542   \n",
       "\n",
       "                                   arbitro  \\\n",
       "0           Jose Antonio Lopez Toca, Spain   \n",
       "1        Guillermo Cuadra Fernandez, Spain   \n",
       "2             Juan Martinez Munuera, Spain   \n",
       "3            Pablo Gonzales Fuertes, Spain   \n",
       "4         José Luis Munuera Montero, Spain   \n",
       "5   Aitor Gorostegui Fernandez Orte, Spain   \n",
       "6             Mateo Busquets Ferrer, Spain   \n",
       "7              Rafael Sanchez Lopez, Spain   \n",
       "8       Alejandro Quintero Gonzalez, Spain   \n",
       "9            Valentin Pizarro Gomez, Spain   \n",
       "10                 Cesar Soto Grado, Spain   \n",
       "11     Raul Martin Gonzalez Frances, Spain   \n",
       "12             Alvaro Moreno Aragon, Spain   \n",
       "13        Oliver de la Fuente Ramos, Spain   \n",
       "14      Damaso Arcediano Monescillo, Spain   \n",
       "15            Andres Fuentes Molina, Spain   \n",
       "16        Luis Mario Milla Alvendiz, Spain   \n",
       "\n",
       "                                              estadio  season  \\\n",
       "0                                     Estadi Nacional    2022   \n",
       "1                       Estádio Cívitas Metropolitano    2022   \n",
       "2                              Coliseum Alfonso Pérez    2022   \n",
       "3   Power Horse Stadium – Estadio de los Juegos Me...    2022   \n",
       "4                               Visit Mallorca Estadi    2022   \n",
       "5                     Estadio Municipal de El Plantío    2022   \n",
       "6                                  Estadio El Alcoraz    2022   \n",
       "7                         Estadio Municipal de Anduva    2022   \n",
       "8                   Estadio Heliodoro Rodríguez Lopéz    2022   \n",
       "9                     Estadio Municipal José Zorrilla    2022   \n",
       "10                          Estadio Benito Villamarín    2022   \n",
       "11                                 Estadio Anxo Carro    2022   \n",
       "12                                Estadio La Rosaleda    2022   \n",
       "13                            Estadio Carlos Belmonte    2022   \n",
       "14                                 Estadio El Toralín    2022   \n",
       "15                      Estadio Municipal de Butarque    2022   \n",
       "16                             Estadio de la Cerámica    2022   \n",
       "\n",
       "    shots_on_goal_local  shots_on_goal_away  shots_off_goal_local  \\\n",
       "0                   1.0                 3.0                   2.0   \n",
       "1                   8.0                 1.0                   4.0   \n",
       "2                   6.0                 7.0                   1.0   \n",
       "3                   0.0                 6.0                   3.0   \n",
       "4                   3.0                 6.0                   5.0   \n",
       "5                   4.0                 5.0                   2.0   \n",
       "6                   4.0                 7.0                   2.0   \n",
       "7                   2.0                 3.0                   6.0   \n",
       "8                   7.0                 2.0                   2.0   \n",
       "9                   5.0                 2.0                   7.0   \n",
       "10                  4.0                 5.0                   3.0   \n",
       "11                  4.0                 1.0                   1.0   \n",
       "12                  3.0                 7.0                  11.0   \n",
       "13                  9.0                 3.0                   3.0   \n",
       "14                  4.0                 3.0                   7.0   \n",
       "15                  6.0                 5.0                   7.0   \n",
       "16                  4.0                 2.0                   3.0   \n",
       "\n",
       "    shots_off_goal_away  total_shots_local  ...  titu-337011.0  titu-337031.0  \\\n",
       "0                  10.0                4.0  ...            0.0            0.0   \n",
       "1                   6.0               18.0  ...            0.0            0.0   \n",
       "2                   1.0               10.0  ...            0.0            0.0   \n",
       "3                   7.0                6.0  ...            0.0            0.0   \n",
       "4                   4.0               14.0  ...            0.0            0.0   \n",
       "5                   1.0                8.0  ...            0.0            0.0   \n",
       "6                  10.0                7.0  ...            0.0            0.0   \n",
       "7                   4.0               11.0  ...            0.0            0.0   \n",
       "8                   0.0               14.0  ...            0.0            0.0   \n",
       "9                   6.0               15.0  ...            0.0            0.0   \n",
       "10                  5.0                8.0  ...            0.0            0.0   \n",
       "11                  7.0                8.0  ...            0.0            0.0   \n",
       "12                  3.0               20.0  ...            0.0            0.0   \n",
       "13                  6.0               14.0  ...            0.0            0.0   \n",
       "14                  2.0               14.0  ...            0.0            0.0   \n",
       "15                  4.0               15.0  ...            0.0            0.0   \n",
       "16                  2.0               10.0  ...            0.0            0.0   \n",
       "\n",
       "    titu-337523.0  titu-338295.0  titu-341700.0  titu-347886.0  titu-380261.0  \\\n",
       "0             0.0            0.0            0.0            0.0            0.0   \n",
       "1             0.0            0.0            0.0            0.0            0.0   \n",
       "2             0.0            0.0            0.0            0.0            0.0   \n",
       "3             0.0            0.0            0.0            0.0            0.0   \n",
       "4             0.0            0.0            0.0            0.0            0.0   \n",
       "5             0.0            0.0            0.0            0.0            0.0   \n",
       "6             0.0            0.0            0.0            0.0            0.0   \n",
       "7             0.0            0.0            0.0            0.0            0.0   \n",
       "8             0.0            0.0            0.0            0.0            0.0   \n",
       "9             0.0            0.0            0.0            0.0            0.0   \n",
       "10            0.0            0.0            0.0            0.0            0.0   \n",
       "11            0.0            0.0            0.0            0.0            0.0   \n",
       "12            0.0            0.0            0.0            0.0            0.0   \n",
       "13            0.0            0.0            0.0            0.0            0.0   \n",
       "14            0.0            0.0            0.0            0.0            0.0   \n",
       "15            0.0            0.0            0.0            0.0            0.0   \n",
       "16            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "    odd_1  odd_x  odd_2  \n",
       "0    2.75   2.90   2.88  \n",
       "1    1.67   3.60   5.25  \n",
       "2    2.75   3.00   2.80  \n",
       "3    3.50   3.60   2.05  \n",
       "4    1.70   3.40   5.75  \n",
       "5    3.50   2.90   2.30  \n",
       "6    3.75   3.00   2.15  \n",
       "7    2.63   2.90   3.00  \n",
       "8    2.50   2.80   3.25  \n",
       "9    2.50   3.20   2.88  \n",
       "10   4.75   3.75   1.73  \n",
       "11   3.50   3.10   2.25  \n",
       "12   2.25   3.00   3.50  \n",
       "13   2.15   2.90   4.00  \n",
       "14   2.60   3.10   2.90  \n",
       "15   1.73   3.10   6.50  \n",
       "16   3.80   3.30   2.05  \n",
       "\n",
       "[17 rows x 3735 columns]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "384 fits failed out of a total of 432.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "96 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 483, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 501, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=12 must be between 0 and min(n_samples, n_features)=11 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "96 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 483, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 501, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=30 must be between 0 and min(n_samples, n_features)=11 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 483, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 501, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=30 must be between 0 and min(n_samples, n_features)=12 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "96 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 483, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 501, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=35 must be between 0 and min(n_samples, n_features)=11 with svd_solver='full'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 378, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 336, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\pipeline.py\", line 870, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 433, in fit_transform\n",
      "    U, S, Vt = self._fit(X)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 483, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 501, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=35 must be between 0 and min(n_samples, n_features)=12 with svd_solver='full'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\gonve\\anaconda3\\envs\\general\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;arbitro&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [&#x27;arbitro&#x27;]),\n",
       "                                                                        (&#x27;estadio&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;target&#x27;,\n",
       "                                                                                          TargetEncoder())]),\n",
       "                                                                         [&#x27;estadio&#x27;])])),\n",
       "                                       (&#x27;pca&#x27;, PCA()),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booste...\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;pca__n_components&#x27;: [12, 30, 35],\n",
       "                         &#x27;xgb__colsample_bytree&#x27;: [0.5, 0.6], &#x27;xgb__gamma&#x27;: [0],\n",
       "                         &#x27;xgb__learning_rate&#x27;: [0.1],\n",
       "                         &#x27;xgb__max_depth&#x27;: [27, 25],\n",
       "                         &#x27;xgb__min_child_weight&#x27;: [1, 2],\n",
       "                         &#x27;xgb__n_estimators&#x27;: [300, 500, 700],\n",
       "                         &#x27;xgb__subsample&#x27;: [0.5, 0.8]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;arbitro&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         [&#x27;arbitro&#x27;]),\n",
       "                                                                        (&#x27;estadio&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;target&#x27;,\n",
       "                                                                                          TargetEncoder())]),\n",
       "                                                                         [&#x27;estadio&#x27;])])),\n",
       "                                       (&#x27;pca&#x27;, PCA()),\n",
       "                                       (&#x27;xgb&#x27;,\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booste...\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;pca__n_components&#x27;: [12, 30, 35],\n",
       "                         &#x27;xgb__colsample_bytree&#x27;: [0.5, 0.6], &#x27;xgb__gamma&#x27;: [0],\n",
       "                         &#x27;xgb__learning_rate&#x27;: [0.1],\n",
       "                         &#x27;xgb__max_depth&#x27;: [27, 25],\n",
       "                         &#x27;xgb__min_child_weight&#x27;: [1, 2],\n",
       "                         &#x27;xgb__n_estimators&#x27;: [300, 500, 700],\n",
       "                         &#x27;xgb__subsample&#x27;: [0.5, 0.8]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;arbitro&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  [&#x27;arbitro&#x27;]),\n",
       "                                                 (&#x27;estadio&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;target&#x27;,\n",
       "                                                                   TargetEncoder())]),\n",
       "                                                  [&#x27;estadio&#x27;])])),\n",
       "                (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;xgb&#x27;,\n",
       "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "                               colsam...\n",
       "                               feature_types=None, gamma=None, gpu_id=None,\n",
       "                               grow_policy=None, importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=None,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=None,\n",
       "                               max_depth=None, max_leaves=None,\n",
       "                               min_child_weight=None, missing=nan,\n",
       "                               monotone_constraints=None, n_estimators=100,\n",
       "                               n_jobs=None, num_parallel_tree=None,\n",
       "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;arbitro&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=False))]),\n",
       "                                 [&#x27;arbitro&#x27;]),\n",
       "                                (&#x27;estadio&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;target&#x27;, TargetEncoder())]),\n",
       "                                 [&#x27;estadio&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">arbitro</label><div class=\"sk-toggleable__content\"><pre>[&#x27;arbitro&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estadio</label><div class=\"sk-toggleable__content\"><pre>[&#x27;estadio&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TargetEncoder</label><div class=\"sk-toggleable__content\"><pre>TargetEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('arbitro',\n",
       "                                                                         Pipeline(steps=[('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                                        sparse=False))]),\n",
       "                                                                         ['arbitro']),\n",
       "                                                                        ('estadio',\n",
       "                                                                         Pipeline(steps=[('target',\n",
       "                                                                                          TargetEncoder())]),\n",
       "                                                                         ['estadio'])])),\n",
       "                                       ('pca', PCA()),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booste...\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None, ...))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'pca__n_components': [12, 30, 35],\n",
       "                         'xgb__colsample_bytree': [0.5, 0.6], 'xgb__gamma': [0],\n",
       "                         'xgb__learning_rate': [0.1],\n",
       "                         'xgb__max_depth': [27, 25],\n",
       "                         'xgb__min_child_weight': [1, 2],\n",
       "                         'xgb__n_estimators': [300, 500, 700],\n",
       "                         'xgb__subsample': [0.5, 0.8]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
